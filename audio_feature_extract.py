# -*- coding: utf-8 -*-
"""audio_feature_extract.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pEZsjKtB15-L5krF43nVJwrELDbFs8A1
"""

from google.colab import drive
drive.mount('/content/gdrive')

# ABI = (5.0447730915 − [0.172*CPPs] − [0.193*Jit] − [1.283*GNEmax-4500 Hz] − [0.396*Hfno-6000 Hz] + [0.01*HNR-D] + [0.017*H1-H2] + [1.473*Shim-dB] − [0.088*Shim] − [68.295*PSD])*2.9257400394

# accoustic breathiness index - to measure breathiness within voice

"""ABI = (5.0447730915 − [0.172*CPPs] − [0.193*Jit] − [1.283*GNEmax-4500 Hz] − [0.396*Hfno-6000 Hz] + [0.01*HNR-D] + [0.017*H1-H2] + [1.473*Shim-dB] − [0.088*Shim] − [68.295*PSD])*2.9257400394"""

import numpy as np
import pandas as pd

data = pd.read_csv('/content/gdrive/My Drive/pd_diagnosis/data_final.csv')
data.head()

audio_df = pd.DataFrame()

import librosa
import numpy as np
import pandas as pd
from scipy.signal import find_peaks, welch

def calculate_jitter(y, sr, fmin, fmax):
    f0, voiced_flag, voiced_probs = librosa.pyin(y, fmin=fmin, fmax=fmax)
    f0 = f0[voiced_flag]
    diff_f0 = np.diff(f0)
    jitter = np.mean(np.abs(diff_f0)) / np.mean(f0)
    return jitter

def calculate_shimmer(y, sr):
    amplitude_envelope = librosa.feature.rms(y=y).flatten()
    diff_amplitude = np.diff(amplitude_envelope)
    shimmer = np.mean(np.abs(diff_amplitude)) / np.mean(amplitude_envelope)
    return shimmer

def calculate_hnr(y, sr):
    harmonic = librosa.effects.harmonic(y)
    percussive = librosa.effects.percussive(y)
    hnr = np.mean(harmonic / (percussive + 1e-10))
    return hnr

def get_cpp(y, sr):
    S = np.abs(librosa.stft(y))
    log_spectrum = np.log(S + 1e-10)  # Add a small value to avoid log(0)
    cepstrum = np.fft.ifft(log_spectrum).real
    cepstrum = cepstrum.flatten()
    peaks, _ = find_peaks(cepstrum)
    return np.max(cepstrum[peaks]) if len(peaks) > 0 else 0

def calculate_psd(y, sr):
    f, Pxx = welch(y, sr, nperseg=1024)
    return np.mean(Pxx)

def calculate_h1_h2(y, sr):
    harmonics = librosa.effects.harmonic(y)
    h1 = harmonics[0]  # First harmonic
    h2 = harmonics[1] if len(harmonics) > 1 else 0  # Second harmonic if exists
    return h1 - h2

def calculate_gne(y, sr, max_freq=4500):
    S, phase = librosa.magphase(librosa.stft(y))
    harmonic = librosa.effects.harmonic(y)
    noise = y - harmonic
    gne = np.mean(librosa.feature.rms(y=harmonic) / (librosa.feature.rms(y=noise) + 1e-10))
    return gne

def calculate_hfno(y, sr, high_freq=6000):
    S = np.abs(librosa.stft(y))
    freqs = librosa.fft_frequencies(sr=sr)
    high_freq_mask = freqs > high_freq
    hf_noise = np.mean(S[high_freq_mask])
    return hf_noise

def process_audio(audio_file):
    y, sr = librosa.load(audio_file)
    fmin, fmax = librosa.note_to_hz('C1'), librosa.note_to_hz('C8')

    # Extracting time-varying features
    volume = librosa.feature.rms(y=y).flatten()
    pitches, magnitudes = librosa.core.piptrack(y=y, sr=sr)
    pitch = pitches[pitches > 0]  # Filter out zero values
    pitch = pitch.flatten()

    zcr = librosa.feature.zero_crossing_rate(y).flatten()
    rms = librosa.feature.rms(y=y).flatten()
    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr).flatten()
    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr).flatten()
    spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr).flatten()

    # Extracting single value features
    jitter = calculate_jitter(y, sr, fmin, fmax)
    shimmer = calculate_shimmer(y, sr)
    hnr_d = calculate_hnr(y, sr)
    cpp = get_cpp(y, sr)
    psd = calculate_psd(y, sr)
    h1_h2 = calculate_h1_h2(y, sr)
    gne_max_4500hz = calculate_gne(y, sr, max_freq=4500)
    hfno_6000hz = calculate_hfno(y, sr, high_freq=6000)
    shim_db = 20 * np.log10(shimmer + 1e-10)

    # Calculate ABI
    abi = (5.0447730915 - (0.172 * cpp) - (0.193 * jitter) - (1.283 * gne_max_4500hz) -
           (0.396 * hfno_6000hz) + (0.01 * hnr_d) + (0.017 * h1_h2) +
           (1.473 * shim_db) - (0.088 * shimmer) - (68.295 * psd)) * 2.9257400394

    # Get recordId
    file_name = os.path.split(audio_file)[-1:][0][:-4]
    recordId = file_name[8:]

    # Creating the DataFrame
    data = [
        recordId,
        np.mean(volume),
        np.std(volume),
        np.mean(pitch),
        np.std(pitch),
        np.mean(zcr),
        np.std(zcr),
        np.mean(rms),
        np.std(rms),
        np.mean(spectral_centroid),
        np.std(spectral_centroid),
        np.mean(spectral_bandwidth),
        np.std(spectral_bandwidth),
        np.mean(spectral_rolloff),
        np.std(spectral_rolloff),
        jitter,
        shimmer,
        hnr_d,
        cpp,
        psd,
        h1_h2,
        gne_max_4500hz,
        hfno_6000hz,
        shim_db,
        abi
    ]

    df = pd.DataFrame(data).T
    return df

def process_audio2(audio_file):
  return 1

audio_df = pd.DataFrame()

audio_df['recordId'] = -1
audio_df['Volume_mean'] = -1
audio_df['Volume_std'] = -1
audio_df['Pitch_mean'] = -1
audio_df['Pitch_std'] = -1
audio_df['ZCR_mean'] = -1
audio_df['ZCR_std'] = -1
audio_df['RMS_mean'] = -1
audio_df['RMS_std'] = -1
audio_df['Spectral_Centroid_mean'] = -1
audio_df['Spectral_Centroid_std'] = -1
audio_df['Spectral_Bandwidth_mean'] = -1
audio_df['Spectral_Bandwidth_std'] = -1
audio_df['Spectral_Rolloff_mean'] = -1
audio_df['Spectral_Rolloff_std'] = -1
audio_df['Jitter'] = -1
audio_df['Shimmer'] = -1
audio_df['HNR_D'] = -1
audio_df['CPP'] = -1
audio_df['PSD'] = -1
audio_df['H1_H2'] = -1
audio_df['GNE_max_4500Hz'] = -1
audio_df['Hfno_6000Hz'] = -1
audio_df['Shim_dB'] = -1
audio_df['ABI'] = -1

audio_df.head()

import os
import librosa
import numpy as np
import pandas as pd
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from PIL import Image
from google.colab import drive
import matplotlib.pyplot as plt

pathAudio = "/content/gdrive/My Drive/pd_diagnosis/Synapse_12-31-2023/Male/TRUE_CONCAT"
pathTest = "/content/gdrive/My Drive/pd_diagnosis/Synapse_12-31-2023/test"

files = librosa.util.find_files(pathAudio, ext=['m4a'])
files = np.asarray(files)
sr=44100
num_failures=0
count = 0
for audio_file in files:
  try:
    count += 1
    if count <= 496:
      print(count)
      continue
    file_name = os.path.split(audio_file)[-1:][0][:-4]
    print(f"Processing: {file_name}")
    audio_this = process_audio(audio_file)
    audio_df = pd.concat([audio_df, audio_this], axis = 0, ignore_index=True)
    print(count)
  except ValueError as err:
      num_failures = num_failures +1
      print(f"Value Error {file_name} err={err}" )
  print(f"Total files failed {num_failures}")

path2 = "/content/gdrive/My Drive/pd_diagnosis/Synapse_12-31-2023/Male/FALSE_CONCAT"

files = librosa.util.find_files(path2, ext=['m4a']) # audio type
files = np.asarray(files)
sr=44100 # sampling rate
num_failures=0
for audio_file in files:
  try:
    count += 1
    if count <= 496:
      print(count)
      continue
    file_name = os.path.split(audio_file)[-1:][0][:-4]
    print(f"Processing: {file_name}")
    audio_this = process_audio(audio_file)
    audio_df = pd.concat([audio_df, audio_this], axis = 0, ignore_index=True)
  except ValueError as err:
      num_failures = num_failures +1
      print(f"Value Error {file_name} err={err}" )
  print(f"Total files failed {num_failures}")

audio_df.head()

audio_df.shape

audio_df['recordId']

audio_df.columns = ['recordId', 'Volume_mean', 'Volume_std', 'Pitch_mean', 'Pitch_std', 'ZCR_mean', 'ZCR_std', 'RMS_mean', 'RMS_std', 'Spectral_Centroid_mean',
                    'Spectral_Centroid_std', 'Spectral_Bandwidth_mean', 'Spectral_Bandwidth_std', 'Spectral_Rolloff_mean', 'Spectral_Rolloff_std', 'Jitter', 'Shimmer',
                    'HNR_D', 'CPP', 'PSD', 'H1_H2', 'GNE_max_4500Hz', 'Hfno_6000Hz', 'Shim_dB', 'ABI']

audio_df.drop_duplicates(subset=['recordId'], keep='first', inplace=True)

audio_df.to_csv('/content/gdrive/My Drive/pd_diagnosis/audio_df.csv')

healthCodes = pd.read_csv("/content/gdrive/My Drive/pd_diagnosis/healthCodes.csv")
healthCodes.head()

audio_codes = pd.merge(audio_df, healthCodes, on='recordId', how='inner')
audio_codes.head()

data = pd.merge(data, audio_codes, on='healthCode', how='inner')
data.head()

data.shape

data.to_csv('/content/gdrive/My Drive/pd_diagnosis/voice_features.csv')

voice_cleaned = pd.read_csv('/content/gdrive/My Drive/pd_diagnosis/voice_cleaned.csv')
voice_cleaned.head()

voice_features = voice_cleaned.drop(['recordId_x', 'healthCode', 'recordId_y', 'Diagnosis', 'Gender'], axis=1)
voice_features.head()

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

normalized_df = pd.DataFrame(scaler.fit_transform(voice_features), columns=voice_features.columns)
normalized_df.head()

age = normalized_df['Age']

age.head()

normalized_df.drop('Age', axis=1, inplace=True)

normalized_df = pd.concat([])

normalized_df = pd.concat([voice_cleaned['healthCode'], normalized_df], axis=1)
normalized_df.head()

normalized_df.shape

voice_cleaned.shape

normalized_df.head()

audio_df.columns

normalized_df.to_csv('/content/gdrive/My Drive/pd_diagnosis/normalized_df.csv')